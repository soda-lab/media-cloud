{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import example_helper\n",
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "from deepmoji.sentence_tokenizer import SentenceTokenizer\n",
    "from deepmoji.model_def import deepmoji_emojis\n",
    "from deepmoji.global_variables import PRETRAINED_PATH, VOCAB_PATH\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import warnings\n",
    "from pymongo import MongoClient\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "host = config['DEFAULT']['IP']\n",
    "port = config['DEFAULT']['MongoDB-Port']\n",
    "\n",
    "client = MongoClient(host, int(port))\n",
    "col = client['Twitter']['twitter-richard-2017']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = col.find({'$text': {'$search': '\"family violence\"'}}, no_cursor_timeout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TEST_SENTENCES = []\n",
    "print('Retrieving Tweets...\\n')\n",
    "n=0\n",
    "for tweet in cursor:\n",
    "    try:\n",
    "        TEST_SENTENCES.append(tweet['doc']['text'].strip().decode('utf-8'))\n",
    "        n += 1\n",
    "        if n % 100 == 0:\n",
    "            print(n, 'finished')\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove meaningless tweets\n",
    "for s in TEST_SENTENCES:\n",
    "    tokens = s.split(' ')\n",
    "    for token in tokens:\n",
    "        if token.startswith('@') or token.startswith('#') or token.startswith('http'):\n",
    "            del token\n",
    "    if len(tokens) == 0:\n",
    "        del s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing using dictionary from /Users/wky/Desktop/projects/media-cloud/DeepMoji/model/vocabulary.json\n",
      "Loading model from /Users/wky/Desktop/projects/media-cloud/DeepMoji/model/deepmoji_weights.hdf5.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 30, 256)      12800000    input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 30, 256)      0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bi_lstm_0 (Bidirectional)       (None, 30, 1024)     3149824     activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bi_lstm_1 (Bidirectional)       (None, 30, 1024)     6295552     bi_lstm_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 30, 2304)     0           bi_lstm_1[0][0]                  \n",
      "                                                                 bi_lstm_0[0][0]                  \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "attlayer (AttentionWeightedAver (None, 2304)         2304        concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Dense)                 (None, 64)           147520      attlayer[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 22,395,200\n",
      "Trainable params: 22,395,200\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Running predictions.\n",
      "Writing results to output/twitter-scores.csv\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "\n",
    "OUTPUT_PATH = 'output/twitter-scores.csv'\n",
    "\n",
    "\n",
    "def top_elements(array, k):\n",
    "    ind = np.argpartition(array, -k)[-k:]\n",
    "    return ind[np.argsort(array[ind])][::-1]\n",
    "\n",
    "\n",
    "maxlen = 30\n",
    "batch_size = 32\n",
    "\n",
    "print('Tokenizing using dictionary from {}'.format(VOCAB_PATH))\n",
    "with open(VOCAB_PATH, 'r') as f:\n",
    "    vocabulary = json.load(f)\n",
    "st = SentenceTokenizer(vocabulary, maxlen)\n",
    "tokenized, _, _ = st.tokenize_sentences(TEST_SENTENCES)\n",
    "\n",
    "print('Loading model from {}.'.format(PRETRAINED_PATH))\n",
    "model = deepmoji_emojis(maxlen, PRETRAINED_PATH)\n",
    "model.summary()\n",
    "\n",
    "print('Running predictions.')\n",
    "prob = model.predict(tokenized)\n",
    "\n",
    "# Find top emojis for each sentence. Emoji ids (0-63)\n",
    "# correspond to the mapping in emoji_overview.png\n",
    "# at the root of the DeepMoji repo.\n",
    "print('Writing results to {}'.format(OUTPUT_PATH))\n",
    "scores = []\n",
    "for i, t in enumerate(TEST_SENTENCES):\n",
    "    t_tokens = tokenized[i]\n",
    "    t_score = [t]\n",
    "    t_prob = prob[i]\n",
    "    ind_top = top_elements(t_prob, 5)\n",
    "    t_score.append(sum(t_prob[ind_top]))\n",
    "    t_score.extend(ind_top)\n",
    "    t_score.extend([t_prob[ind] for ind in ind_top])\n",
    "    scores.append(t_score)\n",
    "\n",
    "with open(OUTPUT_PATH, 'wb') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',', lineterminator='\\n')\n",
    "    writer.writerow(['Text', 'Top5%',\n",
    "                     'Emoji_1', 'Emoji_2', 'Emoji_3', 'Emoji_4', 'Emoji_5',\n",
    "                     'Pct_1', 'Pct_2', 'Pct_3', 'Pct_4', 'Pct_5'])\n",
    "    for i, row in enumerate(scores):\n",
    "        try:\n",
    "            writer.writerow(row)\n",
    "        except Exception:\n",
    "            print(\"Exception at row {}!\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEST_SENTENCES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
